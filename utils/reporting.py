from __future__ import annotations
import json
import os
from typing import Dict, List, Tuple

from services.store import REPORTS_DIR


def generate_markdown_report(report_data: Dict) -> str:
    """å°†æŠ¥å‘Šæ•°æ®è½¬æ¢ä¸º Markdown æ ¼å¼å­—ç¬¦ä¸²"""
    meta = report_data.get("meta", {})
    summary = report_data.get("global_summary", "æš‚æ— æ€»ç»“")
    articles = report_data.get("articles", [])

    md_lines: List[str] = []
    md_lines.append(f"# ğŸ§¬ {meta.get('domain', 'RSS')} AI Daily Brief")
    md_lines.append(f"> ğŸ“… Date: {meta.get('date')} | ğŸ“Š Passed: {meta.get('total_passed')}/{meta.get('total_raw')}\n")

    md_lines.append("## ğŸ“° æœ¬æœŸçœ‹ç‚¹ (Executive Summary)")
    md_lines.append(summary)
    md_lines.append("\n---\n")
    md_lines.append("## ğŸ“š ç²¾é€‰æ–‡ç«  (Selected Articles)\n")

    for idx, art in enumerate(articles, 1):
        ai = art.get("ai_analysis", {})
        title_cn = ai.get("title_cn", art.get("title"))
        score = ai.get("score", 0)

        score_icon = "ğŸŒŸ" if score >= 9 else ("ğŸ”¥" if score >= 7 else "ğŸ“„")

        md_lines.append(f"### {idx}. {title_cn} {score_icon} {score}")
        md_lines.append(f"**ğŸ”— åŸæ–‡é“¾æ¥**: [{art.get('title')}]({art.get('link')})")
        if ai.get("one_sentence"):
            md_lines.append(f"**ğŸ“Œ ä¸€å¥è¯çœ‹ç‚¹**: {ai.get('one_sentence')}")

        kws = ai.get("keywords", [])
        if isinstance(kws, list):
            kw_text = ", ".join(kws)
        else:
            kw_text = str(kws)
        md_lines.append(f"**ğŸ·ï¸ æ ‡ç­¾**: {kw_text}")
        md_lines.append(f"**ğŸ“ æ‘˜è¦**: {ai.get('summary', 'æ— ')}")

        if ai.get("reason"):
            md_lines.append(f"> *ğŸ’¡ è¯„åˆ†ä¾æ®: {ai.get('reason')}*")

        md_lines.append("\n---\n")

    md_lines.append("\n*Generated by AI RSS Flow*")
    return "\n".join(md_lines)


def load_all_reports(limit: int | None = None) -> List[Dict]:
    files = []
    if os.path.isdir(REPORTS_DIR):
        for name in os.listdir(REPORTS_DIR):
            if name.endswith(".json"):
                files.append(os.path.join(REPORTS_DIR, name))
    files.sort(key=lambda p: os.path.getmtime(p), reverse=True)

    reports: List[Dict] = []
    for p in (files[:limit] if limit else files):
        try:
            with open(p, "r", encoding="utf-8") as f:
                reports.append(json.load(f))
        except Exception:
            continue
    return reports


def aggregate_history_stats(limit: int | None = 20) -> Dict:
    """ä»å†å²æŠ¥å‘Šä¸­æ±‡æ€»ç»Ÿè®¡ï¼ˆç±»åˆ«åˆ†å¸ƒã€æ¯æœŸæ–‡ç« æ•°ã€æ€»æŠ¥å‘Šæ•°ç­‰ï¼‰"""
    reports = load_all_reports(limit=limit)
    category_count: Dict[str, int] = {}
    per_issue_passed: List[Tuple[str, int]] = []

    for r in reports:
        meta = r.get("meta", {})
        per_issue_passed.append((meta.get("date", ""), int(meta.get("total_passed", 0))))
        for art in r.get("articles", []):
            cat = art.get("ai_analysis", {}).get("category", "OTHER")
            category_count[cat] = category_count.get(cat, 0) + 1

    total_reports = len(reports)
    return {
        "category_count": category_count,
        "per_issue_passed": per_issue_passed,
        "total_reports": total_reports,
    }
